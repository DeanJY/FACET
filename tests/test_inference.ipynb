{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from EvEye.utils.scripts.load_config import load_config\n",
    "from EvEye.dataset.dataset_factory import make_dataset\n",
    "from EvEye.model.model_factory import make_model\n",
    "from EvEye.utils.scripts.load_config import load_config\n",
    "from EvEye.dataset.DavisEyeCenter.losses import process_detector_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/mnt/data2T/junyuan/eye-tracking/configs/TestTextDavisEyeDataset_TennSt.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(config_path)\n",
    "testDataset = make_dataset(config['dataset'])\n",
    "model = make_model(config['model'])\n",
    "model.load_state_dict(\n",
    "    torch.load(config[\"test\"][\"ckpt_path\"])[\"state_dict\"]\n",
    "    )\n",
    "device = config[\"test\"][\"map_location\"]\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frames = testDataset[0].unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.streaming_inference(model, event_frames)\n",
    "pred = process_detector_prediction(pred)\n",
    "pred = pred.squeeze(0)\n",
    "pred[0] *= 346\n",
    "pred[1] *= 260\n",
    "predictions_numpy = pred.detach().cpu().numpy().T.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arange = np.arange(predictions_numpy.shape[0])\n",
    "predictions_numpy = np.concatenate([arange[:, None], predictions_numpy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions_numpy, columns=[\"row_id\", \"x\", \"y\"])\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import natsort\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from tonic import transforms\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from EvEye.utils.tonic.functional.CutMaxCount import cut_max_count\n",
    "from EvEye.utils.scripts.load_config import load_config\n",
    "from EvEye.model.model_factory import make_model\n",
    "from EvEye.dataset.DavisEyeCenter.losses import process_detector_prediction\n",
    "from EvEye.utils.tonic.slicers.SliceEventsAtIndices import slice_events_at_timepoints\n",
    "from EvEye.utils.tonic.functional.ToFrameStack import to_frame_stack_numpy\n",
    "from EvEye.utils.processor.TxtProcessor import TxtProcessor\n",
    "from EvEye.utils.visualization.visualization import save_image\n",
    "from EvEye.utils.visualization.visualization import visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '/mnt/data2T/junyuan/eye-tracking/configs/TestTextDavisEyeDataset_TennSt.yaml'\n",
    "txt_path = Path(\"/mnt/data2T/junyuan/eye-tracking/datasets/DavisEyeCenterDataset/test/data/user43_left_session_1_0_1_events.txt\")\n",
    "label_path = Path(\"/mnt/data2T/junyuan/eye-tracking/datasets/DavisEyeCenterDataset/test/label/user43_left_session_1_0_1_centers.txt\")\n",
    "rgb_path = '/mnt/data2T/junyuan/eye-tracking/datasets/DavisEyeCenterDatasetFrames/user43_left_session_1_0_1'\n",
    "output_path = '/mnt/data2T/junyuan/eye-tracking/outputs/InferenceResultsTest_4'\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = TxtProcessor(txt_path).load_events_from_txt()\n",
    "labels = TxtProcessor(label_path).load_labels_from_txt()\n",
    "config = load_config(config_path)\n",
    "model = make_model(config['model'])\n",
    "model.load_state_dict(\n",
    "    torch.load(config[\"test\"][\"ckpt_path\"])[\"state_dict\"]\n",
    "    )\n",
    "device = config[\"test\"][\"map_location\"]\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = (346, 260, 2)\n",
    "time_window = 40000\n",
    "events_interpolation = \"causal_linear\"\n",
    "max_count = 5\n",
    "spatial_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_downsampled = transforms.Downsample(spatial_factor=spatial_factor)(events)\n",
    "sensor_size_downsampled = (\n",
    "    int(sensor_size[0] * spatial_factor),\n",
    "    int(sensor_size[1] * spatial_factor),\n",
    "    int(sensor_size[2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_first_flag = False\n",
    "start_time_first = max(events['t'][0], labels['t'][0] - time_window)\n",
    "end_time_first = labels['t'][0]\n",
    "if start_time_first >= end_time_first:\n",
    "    labels = labels[1:]\n",
    "    start_time_first = max(events['t'][0], labels['t'][0] - time_window)\n",
    "    end_time_first = labels['t'][0]\n",
    "    delete_first_flag = True\n",
    "assert start_time_first < end_time_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_segment_first_downsampled = slice_events_at_timepoints(events_downsampled, start_time_first, end_time_first)\n",
    "frame_first_downsampled = to_frame_stack_numpy(event_segment_first_downsampled, sensor_size_downsampled, 1, events_interpolation)\n",
    "event_segment_others_downsampled = slice_events_at_timepoints(events_downsampled, end_time_first, labels['t'][-1])\n",
    "frame_others_downsampled = to_frame_stack_numpy(event_segment_others_downsampled, sensor_size_downsampled, labels.shape[0]-1, events_interpolation)\n",
    "event_frames_downsampled = np.concatenate([frame_first_downsampled, frame_others_downsampled], axis=0)\n",
    "cut_max_count(event_frames_downsampled, max_count, True)\n",
    "event_frames_pred = torch.from_numpy(event_frames_downsampled).moveaxis(0, 1).to(torch.float32).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_segment_first = slice_events_at_timepoints(events, start_time_first, end_time_first)\n",
    "frame_first = to_frame_stack_numpy(event_segment_first, sensor_size, 1, events_interpolation)\n",
    "event_segment_others = slice_events_at_timepoints(events, end_time_first, labels['t'][-1])\n",
    "frame_others = to_frame_stack_numpy(event_segment_others, sensor_size, labels.shape[0]-1, events_interpolation)\n",
    "event_frames = np.concatenate([frame_first, frame_others], axis=0)\n",
    "cut_max_count(event_frames, max_count, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frames.shape, event_frames_downsampled.shape,  event_frames_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.streaming_inference(model, event_frames_pred)\n",
    "pred = process_detector_prediction(pred)\n",
    "pred = pred.squeeze(0)\n",
    "pred[0] *= 346\n",
    "pred[1] *= 260\n",
    "predictions_numpy = pred.detach().cpu().numpy().T.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = [image for image in os.listdir(rgb_path) if image.endswith('.png')]\n",
    "images = natsort.natsorted([os.path.join(rgb_path, image) for image in images_path])\n",
    "if delete_first_flag:\n",
    "    images = images[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert predictions_numpy.shape[0] == labels.shape[0] == len(images)\n",
    "for index in tqdm(range(len(images)), desc=\"Saving images ...\"):\n",
    "    image = cv2.imread(images[index])\n",
    "    event_frame = visualize(event_frames[index])\n",
    "    center_x, center_y = labels['x'][index], labels['y'][index]\n",
    "    pred_x, pred_y = predictions_numpy[index]\n",
    "    event_frame = cv2.circle(event_frame, (int(center_x), int(center_y)), 3, (0, 255, 0), -1)\n",
    "    event_frame = cv2.circle(event_frame, (int(pred_x), int(pred_y)), 3, (255, 255, 255), -1)\n",
    "    image = cv2.circle(image, (int(center_x), int(center_y)), 3, (0, 255, 0), -1)\n",
    "    image = cv2.circle(image, (int(pred_x), int(pred_y)), 3, (255, 255, 255), -1)\n",
    "    combined_image = np.concatenate([image, event_frame], axis=1)\n",
    "    save_image(combined_image, f\"{output_path}/{index:04}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
