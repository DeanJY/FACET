{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "from torch.nn.modules.utils import _pair\n",
    "from torch.onnx import register_custom_op_symbolic\n",
    "from EvEye.model.DavisEyeEllipse.EPNet.EPNet import EPNet\n",
    "from EvEye.model.DavisEyeCenter.TennSt import TennSt\n",
    "from EvEye.model.DavisEyeEllipse.ElNet.ElNet import Creat_MyNet\n",
    "# from EvEye.model.DavisEyeEllipse.UNet.UNet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/mnt/data2T/junyuan/eye-tracking/logs/EPNet_FixedCount5000_TrigERAugFPNdw/version_0/checkpoints/epoch=53-val_mean_distance=0.2249.ckpt\"\n",
    "# output_path = \"/mnt/data2T/junyuan/eye-tracking/outputs/EPNetFPNdw.onnx\"\n",
    "# ckpt = torch.load(model_path)\n",
    "# model = EPNet(input_channels=2,head_dict= { \"hm\": 1, \"ab\": 2, \"trig\": 2, \"reg\": 2, \"mask\": 1 },mode=\"fpn_dw\")\n",
    "# model.load_state_dict(ckpt['state_dict'])\n",
    "# model.eval()\n",
    "# dummy_input = torch.randn(1, 2, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/mnt/data2T/junyuan/eye-tracking/weights/96.89%-FixedCount5000-Down-Aug-NoFlip/checkpoints/epochepoch=47-val_p10_accval_p10_acc=0.9689.ckpt\"\n",
    "output_path = \"/mnt/data2T/junyuan/eye-tracking/outputs/TennSt.onnx\"\n",
    "ckpt = torch.load(model_path)\n",
    "model = TennSt(\n",
    "    channels=[2, 8, 16, 32, 48, 64, 80, 96, 112, 128, 256],\n",
    "    t_kernel_size=5,\n",
    "    n_depthwise_layers=4,\n",
    "    detector_head=True,\n",
    "    detector_depthwise=True,\n",
    "    full_conv3d=False,\n",
    "    norms=\"mixed\",\n",
    "    activity_regularization=0,\n",
    ")\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model.eval()\n",
    "dummy_input = torch.rand(1, 2, 1, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dcnv2_symbolic(g, input, offset, mask, weight, bias, stride, padding, dilation, deformable_groups):\n",
    "#     stride = _pair(stride)\n",
    "#     padding = _pair(padding)\n",
    "#     dilation = _pair(dilation)\n",
    "#     return g.op(\n",
    "#         \"DCNv2_2\",\n",
    "#         input,\n",
    "#         offset,\n",
    "#         mask,\n",
    "#         weight,\n",
    "#         bias,\n",
    "#         stride_i=stride,\n",
    "#         padding_i=padding,\n",
    "#         dilation_i=dilation,\n",
    "#         deformable_groups_i=deformable_groups,\n",
    "#     )\n",
    "\n",
    "# register_custom_op_symbolic('::DCNv2_2', dcnv2_symbolic, 17)\n",
    "\n",
    "# model_path = \"/mnt/data2T/junyuan/eye-tracking/logs/ElNet_FixedCount5000/version_0/checkpoints/epoch=00-val_mean_distance=0.6273.ckpt\"\n",
    "# output_path = \"/mnt/data2T/junyuan/eye-tracking/outputs/ElNet.onnx\"\n",
    "# ckpt = torch.load(model_path)\n",
    "# model = Creat_MyNet(\n",
    "#         base_name=\"dla34\",\n",
    "#         heads={\"hm\": 1, \"ab\": 2, \"ang\": 1, \"trig\": 2, \"reg\": 2, \"mask\": 1},\n",
    "#         pretrained=True,\n",
    "#         down_ratio=4,\n",
    "#         final_kernel=1,\n",
    "#         last_level=5,\n",
    "#         head_conv=256,\n",
    "#         out_channel=0,\n",
    "#     )\n",
    "# model.load_state_dict(ckpt['state_dict'])\n",
    "# model.eval()\n",
    "# dummy_input = torch.randn(1, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = \"/mnt/data2T/junyuan/eye-tracking/logs/RGBUNet/version_0/checkpoints/epoch=27-val_mean_distance=0.3231.ckpt\"\n",
    "# output_path = \"/mnt/data2T/junyuan/eye-tracking/outputs/UNet.onnx\"\n",
    "# ckpt = torch.load(model_path)\n",
    "# model = UNet(n_channels=1,n_classes=2)\n",
    "# model.load_state_dict(ckpt['state_dict'])\n",
    "# model.eval()\n",
    "# dummy_input = torch.randn(1, 1, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,               # 模型\n",
    "    dummy_input,         # 示例输入\n",
    "    output_path,  # 输出文件名\n",
    "    export_params=True,  # 存储模型参数\n",
    "    opset_version=17,    # ONNX 版本\n",
    "    do_constant_folding=True,  # 是否执行常量折叠优化\n",
    "    input_names=['input'],    # 输入名称\n",
    "    output_names=['output'],   # 输出名称\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyuan/anaconda3/envs/EvEye/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/data2T/junyuan/eye-tracking/EvEye/model/DavisEyeEllipse/ElNet/ElNet.py:826: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if train:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.modules.utils import _pair\n",
    "import _ext as _backend\n",
    "from DCNv2.dcn_v2 import _DCNv2\n",
    "from EvEye.model.DavisEyeEllipse.ElNet.ElNet import Creat_MyNet\n",
    "# 注册自定义操作符\n",
    "# from torch.onnx import register_custom_op_symbolic\n",
    "# register_custom_op_symbolic('mydomain::DCNv2_2', _DCNv2.symbolic, 17)\n",
    "\n",
    "# 加载模型和权重\n",
    "model_path = \"/mnt/data2T/junyuan/eye-tracking/logs/ElNet_FixedCount5000/version_0/checkpoints/epoch=00-val_mean_distance=0.6273.ckpt\"\n",
    "ckpt = torch.load(model_path)\n",
    "model = Creat_MyNet(\n",
    "    base_name=\"dla34\",\n",
    "    heads={\"hm\": 1, \"ab\": 2, \"ang\": 1, \"trig\": 2, \"reg\": 2, \"mask\": 1},\n",
    "    pretrained=True,\n",
    "    down_ratio=4,\n",
    "    final_kernel=1,\n",
    "    last_level=5,\n",
    "    head_conv=256,\n",
    "    out_channel=0,\n",
    ")\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# 示例输入\n",
    "dummy_input = torch.randn(1, 3, 256, 256)\n",
    "\n",
    "# 导出模型\n",
    "output_path = \"/mnt/data2T/junyuan/eye-tracking/outputs/ElNet.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    output_path,\n",
    "    export_params=True,\n",
    "    opset_version=17,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    # verbose=True,\n",
    "    operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "No Op registered for DCNv2 with domain_version of 17\n\n==> Context: Bad node spec for node. Name: /dla_up/ida_0/proj_1/conv/DCNv2 OpType: DCNv2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/mnt/data2T/junyuan/eye-tracking/EvEye/utils/scripts/exportONNX.ipynb 单元格 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.1.7/mnt/data2T/junyuan/eye-tracking/EvEye/utils/scripts/exportONNX.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39monnx\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.1.7/mnt/data2T/junyuan/eye-tracking/EvEye/utils/scripts/exportONNX.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m onnx_model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m/mnt/data2T/junyuan/eye-tracking/outputs/ElNet.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.1.7/mnt/data2T/junyuan/eye-tracking/EvEye/utils/scripts/exportONNX.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m onnx\u001b[39m.\u001b[39;49mchecker\u001b[39m.\u001b[39;49mcheck_model(onnx_model)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.1.7/mnt/data2T/junyuan/eye-tracking/EvEye/utils/scripts/exportONNX.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo Error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.1.7/mnt/data2T/junyuan/eye-tracking/EvEye/utils/scripts/exportONNX.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(onnx.helper.printable_graph(onnx_model.graph))\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/EvEye/lib/python3.10/site-packages/onnx/checker.py:179\u001b[0m, in \u001b[0;36mcheck_model\u001b[0;34m(model, full_check, skip_opset_compatibility_check, check_custom_domain)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mgetsizeof(protobuf_string) \u001b[39m>\u001b[39m MAXIMUM_PROTOBUF:\n\u001b[1;32m    176\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    177\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis protobuf of onnx model is too large (>2GB). Call check_model with model path instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m     )\n\u001b[0;32m--> 179\u001b[0m C\u001b[39m.\u001b[39;49mcheck_model(\n\u001b[1;32m    180\u001b[0m     protobuf_string,\n\u001b[1;32m    181\u001b[0m     full_check,\n\u001b[1;32m    182\u001b[0m     skip_opset_compatibility_check,\n\u001b[1;32m    183\u001b[0m     check_custom_domain,\n\u001b[1;32m    184\u001b[0m )\n",
      "\u001b[0;31mValidationError\u001b[0m: No Op registered for DCNv2 with domain_version of 17\n\n==> Context: Bad node spec for node. Name: /dla_up/ida_0/proj_1/conv/DCNv2 OpType: DCNv2"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"/mnt/data2T/junyuan/eye-tracking/outputs/ElNet.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"No Error\")\n",
    "# print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
