{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "import tonic.functional as toc\n",
    "\n",
    "from EvEye.utils.scripts.CacheFrameStack import load_memmap\n",
    "from EvEye.utils.dvs_common_utils.representation.TorchFrameStack import (\n",
    "    TorchFrameStack,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheDavisEyeCenterDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_path: Path | str,\n",
    "        split=\"train\", \n",
    "        time_window=40000, \n",
    "        frames_per_segment=50,\n",
    "        spatial_downsample=(2, 2),\n",
    "        events_interpolation=\"bilinear\",  # 'bilinear', 'nearest', 'causal_linear'\n",
    "    ):\n",
    "        assert time_window == 40000\n",
    "        self.root_path = Path(root_path)\n",
    "        self.split = split\n",
    "        self.time_window = time_window\n",
    "        self.frames_per_segment = frames_per_segment\n",
    "        self.time_window_per_segment = time_window * frames_per_segment\n",
    "        self.spatial_downsample = spatial_downsample\n",
    "        self.events_interpolation = events_interpolation\n",
    "        \n",
    "        self.events, self.labels = [], []\n",
    "        self.num_frames_list, self.num_segments_list = [], []\n",
    "\n",
    "        self.data_base_path: Path = self.root_path / self.split / \"cached_data\"\n",
    "        self.label_base_path: Path = self.root_path / self.split / \"cached_label\"\n",
    "        self.data_paths: list = natsorted(\n",
    "            self.data_base_path.glob(\"events_batch_*.memmap\")\n",
    "        )\n",
    "        self.label_paths: list = natsorted(\n",
    "            self.label_base_path.glob(\"labels_batch_*.memmap\")\n",
    "        )\n",
    "        self.data_info_paths: list = natsorted(\n",
    "            self.data_base_path.glob(\"events_info_batch_*.txt\")\n",
    "        )\n",
    "        self.label_info_paths: list = natsorted(\n",
    "            self.label_base_path.glob(\"labels_info_batch_*.txt\")\n",
    "        )\n",
    "        self.data_indices_paths: list = natsorted(\n",
    "            self.data_base_path.glob(\"events_indices_batch_*.memmap\")\n",
    "        )\n",
    "        self.label_indices_paths: list = natsorted(\n",
    "            self.label_base_path.glob(\"labels_indices_batch_*.memmap\")\n",
    "        )\n",
    "        self.data_indices_info_paths = natsorted(\n",
    "            self.data_base_path.glob(\"events_indices_info_batch_*.txt\")\n",
    "        )\n",
    "        self.label_indices_info_paths = natsorted(\n",
    "            self.label_base_path.glob(\"labels_indices_info_batch_*.txt\")\n",
    "        )\n",
    "        for (\n",
    "            data_path,\n",
    "            label_path,\n",
    "            data_info_path,\n",
    "            label_info_path,\n",
    "            data_indices_path,\n",
    "            label_indices_path,\n",
    "            data_indices_info_path,\n",
    "            label_indices_info_path,\n",
    "        ) in tqdm(\n",
    "            zip(\n",
    "                self.data_paths,\n",
    "                self.label_paths,\n",
    "                self.data_info_paths,\n",
    "                self.label_info_paths,\n",
    "                self.data_indices_paths,\n",
    "                self.label_indices_paths,\n",
    "                self.data_indices_info_paths,\n",
    "                self.label_indices_info_paths,\n",
    "            ),\n",
    "            total=len(self.data_paths),\n",
    "            desc=\"Loading data...\",\n",
    "        ):\n",
    "            events = load_memmap(data_path, data_info_path)\n",
    "            events_indices = load_memmap(data_indices_path, data_indices_info_path)\n",
    "            labels = load_memmap(label_path, label_info_path)\n",
    "            labels_indices = load_memmap(\n",
    "                label_indices_path, label_indices_info_path\n",
    "            )\n",
    "            for indice in events_indices:\n",
    "                event = events[:, indice[0] : indice[1]]\n",
    "                self.events.append(event)\n",
    "\n",
    "            for indice in labels_indices:\n",
    "                num_frames = indice[1] - indice[0]\n",
    "                self.num_frames_list.append(num_frames)\n",
    "                self.num_segments_list.append(num_frames // frames_per_segment)\n",
    "                label = labels[:, indice[0] : indice[1]]\n",
    "                self.labels.append(label)\n",
    "        self.total_segments = sum(self.num_segments_list)\n",
    "\n",
    "    def get_index(self, file_lens, index):\n",
    "        file_lens_cumsum = np.cumsum(np.array(file_lens))\n",
    "        file_id = np.searchsorted(file_lens_cumsum, index, side=\"right\")\n",
    "        sample_id = index - file_lens_cumsum[file_id - 1] if file_id > 0 else index\n",
    "\n",
    "        return file_id, sample_id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.total_segments\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_id, segment_id = self.get_index(self.num_segments_list, index)\n",
    "        event, label = self.events[file_id], self.labels[file_id]\n",
    "        start_time = (\n",
    "                label[0][0] + segment_id * self.time_window * self.frames_per_segment\n",
    "            )\n",
    "        end_time = start_time + self.time_window * self.frames_per_segment\n",
    "\n",
    "        start_event_id = np.searchsorted(event[3], start_time, side=\"left\")\n",
    "        end_event_id = np.searchsorted(event[3], end_time, side=\"left\")\n",
    "        event_segment = event[:, start_event_id:end_event_id]\n",
    "        event_segment = np.array(event_segment)\n",
    "        event_segment[-1] -= start_time\n",
    "        num_frames = self.frames_per_segment\n",
    "        event_segment = torch.from_numpy(event_segment)\n",
    "        # print(event_segment.shape)\n",
    "        event_frame = TorchFrameStack(\n",
    "                events=event_segment,\n",
    "                size=(\n",
    "                    260 // self.spatial_downsample[0],\n",
    "                    346 // self.spatial_downsample[1],\n",
    "                ),\n",
    "                num_frames=num_frames,\n",
    "                spatial_downsample=self.spatial_downsample,\n",
    "                temporal_downsample=self.time_window,\n",
    "                mode=self.events_interpolation,\n",
    "            )\n",
    "        event_frame = event_frame.moveaxis(0, 1)\n",
    "        event_frame = event_frame.numpy()\n",
    "\n",
    "        start_label_id = segment_id * self.frames_per_segment\n",
    "        end_label_id = start_label_id + self.frames_per_segment\n",
    "        label_segment = label[:, start_label_id:end_label_id]\n",
    "        label_x = (label_segment[1] / 2).round()\n",
    "        label_y = (label_segment[2] / 2).round()\n",
    "        label_coord = np.vstack([label_x, label_y])\n",
    "\n",
    "        closeness = 1- np.array(label_segment[3])\n",
    "\n",
    "        return event_frame, label_coord, closeness\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data...: 100%|██████████| 1/1 [00:00<00:00, 40.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = CacheDavisEyeCenterDataset(\n",
    "    root_path=\"/mnt/data2T/junyuan/eye-tracking/testDataset\",\n",
    "    split=\"train\", \n",
    "    time_window=40000, \n",
    "    frames_per_segment=50,\n",
    "    spatial_downsample=(2, 2),\n",
    "    events_interpolation=\"bilinear\",  # 'bilinear', 'nearest', 'causal_linear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 50, 130, 173)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "# for i, (x, y, z) in enumerate(dataloader):\n",
    "#     print(f\"Batch {i}:\")\n",
    "#     print(f\"Data shape: {x.shape}\")\n",
    "#     print(f\"Data dtype: {x.dtype}\")\n",
    "#     print(f\"Label shape: {y.shape}\")\n",
    "#     print(f\"Label dtype: {y.dtype}\")\n",
    "#     print(f\"Close shape: {z.shape}\")\n",
    "#     print(f\"Close dtype: {z.dtype}\")\n",
    "#     # print(f'Input data: {x}')\n",
    "#     # print(f'Output data: {y}')\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82.0, 68.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1][0][35], dataset[0][1][1][35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving data: 100%|██████████| 154/154 [00:26<00:00,  5.84it/s]\n"
     ]
    }
   ],
   "source": [
    "output_data_path = \"/mnt/data2T/junyuan/eye-tracking/np_data\"\n",
    "output_label_path = \"/mnt/data2T/junyuan/eye-tracking/np_label\"\n",
    "output_close_path = \"/mnt/data2T/junyuan/eye-tracking/np_close\"\n",
    "os.makedirs(output_data_path, exist_ok=True)\n",
    "os.makedirs(output_label_path, exist_ok=True)\n",
    "os.makedirs(output_close_path, exist_ok=True)\n",
    "for i in tqdm(range(len(dataset)), desc=\"Saving data\"):\n",
    "    # 获取数据\n",
    "    data, label, close = dataset[i]\n",
    "\n",
    "    # 分别保存 data, label, close\n",
    "    np.save(f\"{output_data_path}/{i}.npy\", data)\n",
    "    np.save(f\"{output_label_path}/{i}.npy\", label)\n",
    "    np.save(f\"{output_close_path}/{i}.npy\", close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 50, 130, 173)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"/mnt/data2T/junyuan/eye-tracking/np_data/0.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 50, 130, 173), (2, 50), (50,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape, dataset[0][1].shape, dataset[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(data, dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_arrays(arrays):\n",
    "    total_length = sum(arr.shape[1] for arr in arrays)\n",
    "    merged_array = np.zeros((arrays[0].shape[0], total_length))\n",
    "    indices = []\n",
    "    current_index = 0\n",
    "    for arr in tqdm(arrays, desc=\"Merging arrays\"):\n",
    "        end_index = current_index + arr.shape[1]\n",
    "        merged_array[:, current_index:end_index] = arr\n",
    "        indices.append((current_index, end_index))\n",
    "        current_index = end_index\n",
    "    return merged_array, indices\n",
    "\n",
    "def create_memmap(data, data_file, info_file):\n",
    "    mmap = np.memmap(data_file, dtype=data.dtype, mode='w+', shape=data.shape)\n",
    "    mmap[:] = data\n",
    "    mmap.flush() \n",
    "    with open(info_file, 'w') as f:\n",
    "        f.write(f\"Data shape: {data.shape}\\n\")\n",
    "        f.write(f\"Data dtype: {data.dtype}\\n\")\n",
    "    return mmap\n",
    "\n",
    "def load_memmap(data_file, info_file):\n",
    "    with open(info_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        shape_line = lines[0].strip()\n",
    "        dtype_line = lines[1].strip()\n",
    "        shape_str = shape_line.split(': ')[1]\n",
    "        shape = tuple(map(int, shape_str.strip('()').split(',')))\n",
    "        dtype_str = dtype_line.split(': ')[1]\n",
    "        dtype = np.dtype(dtype_str)\n",
    "    mmap = np.memmap(data_file, dtype=dtype, mode='r', shape=shape)\n",
    "    return mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging arrays: 100%|██████████| 2/2 [00:00<00:00,  3.82it/s]\n",
      "Merging arrays: 100%|██████████| 2/2 [00:00<00:00, 9078.58it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_events, events_indices = merge_arrays(dataset.events)\n",
    "merged_labels, labels_indices = merge_arrays(dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_memmap = create_memmap(merged_events, 'events.memmap', 'events_info.txt')\n",
    "labels_memmap = create_memmap(merged_labels, 'labels.memmap', 'labels_info.txt')\n",
    "events_indices_memmap = create_memmap(np.array(events_indices), 'events_indices.memmap', 'events_indices_info.txt')\n",
    "labels_indices_memmap = create_memmap(np.array(labels_indices), 'labels_indices.memmap', 'labels_indices_info.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = load_memmap('events.memmap', 'events_info.txt')\n",
    "events_indices = load_memmap('events_indices.memmap', 'events_indices_info.txt')\n",
    "labels = load_memmap('labels.memmap', 'labels_info.txt')\n",
    "labels_indices = load_memmap('labels_indices.memmap', 'labels_indices_info.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 18522866), (4, 7764))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[   0, 5070],\n",
       "        [5070, 7764]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = labels[:, labels_indices[1][0]:labels_indices[1][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2694)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
