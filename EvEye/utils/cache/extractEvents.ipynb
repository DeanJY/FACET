{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from EvEye.utils.tonic.functional.ToFrameStack import to_frame_stack_numpy\n",
    "from EvEye.utils.tonic.slicers.SliceEventsAtIndices import slice_events_at_timepoints\n",
    "from EvEye.utils.tonic.slicers.SliceWithTimestampAndCount import (\n",
    "    slice_events_by_timestamp_and_count,\n",
    ")\n",
    "from EvEye.utils.cache.MemmapCacheStructedEvents import (\n",
    "    load_memmap,\n",
    ")\n",
    "from EvEye.utils.processor.TxtProcessor import TxtProcessor \n",
    "from EvEye.utils.cache.MemmapCacheStructedEvents import *\n",
    "from EvEye.utils.visualization.visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(\"/mnt/data2T/junyuan/Datasets/datasets/MemmapDavisEyeEllipseDataset\")\n",
    "data_path = root_path / \"cached_data\"\n",
    "ellipse_path = root_path / \"cached_ellipse\"\n",
    "time_window = 10000\n",
    "events_count = 1000\n",
    "sensor_size = (346, 260, 2)\n",
    "events_interpolation = \"causal_linear\"\n",
    "num_train_frames = 20000\n",
    "num_val_frames = 5000\n",
    "batch_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_events(file_id):\n",
    "    batch_id = file_id // 50\n",
    "    event_id = file_id % 50\n",
    "    events_batch_path = data_path / f\"events_batch_{batch_id}.memmap\"\n",
    "    events_info_path = data_path / f\"events_batch_info_{batch_id}.txt\"\n",
    "    event_indices_path = data_path / f\"events_indices_{batch_id}.npy\"\n",
    "    events = load_memmap(events_batch_path, events_info_path)\n",
    "    start_index, end_index = np.load(event_indices_path)[event_id]\n",
    "    event = events[start_index:end_index]\n",
    "\n",
    "    return event\n",
    "\n",
    "def load_events_from_txt(txt_path):\n",
    "    events = TxtProcessor(txt_path).load_events_from_txt()\n",
    "\n",
    "    return events\n",
    "\n",
    "def load_event_segment(index, data_base_path, batch_size=5000):\n",
    "    data_base_path = Path(data_base_path)\n",
    "    batch_id = index // batch_size\n",
    "    event_id = index % batch_size\n",
    "    events_batch_path = data_base_path / f\"events_batch_{batch_id}.memmap\"\n",
    "    events_info_path = data_base_path / f\"events_batch_info_{batch_id}.txt\"\n",
    "    event_indices_path = data_base_path / f\"events_indices_{batch_id}.npy\"\n",
    "    events = load_memmap(events_batch_path, events_info_path)\n",
    "    start_index, end_index = np.load(event_indices_path)[event_id]\n",
    "    event_segment = events[start_index:end_index]\n",
    "\n",
    "    return event_segment\n",
    "\n",
    "\n",
    "def load_ellipse(index, ellipse_base_path):\n",
    "    ellipse_base_path = Path(ellipse_base_path)\n",
    "    ellipses_path = ellipse_base_path / f\"ellipses_batch_0.memmap\"\n",
    "    ellipses_info_path = ellipse_base_path / f\"ellipses_batch_info_0.txt\"\n",
    "    ellipses = load_memmap(ellipses_path, ellipses_info_path)\n",
    "    ellipse = ellipses[index]\n",
    "\n",
    "    return ellipse\n",
    "\n",
    "\n",
    "def get_nums(ellipse_path):\n",
    "    num_frames_list = []\n",
    "\n",
    "    ellipses_list = load_cached_structed_ellipses(ellipse_path)\n",
    "    for ellipses in ellipses_list:\n",
    "        num_frames_list.append(len(ellipses))\n",
    "\n",
    "    return num_frames_list, sum(num_frames_list)\n",
    "\n",
    "\n",
    "def get_index(file_lens, index):\n",
    "    file_lens_cumsum = np.cumsum(np.array(file_lens))\n",
    "    file_id = np.searchsorted(file_lens_cumsum, index, side=\"right\")\n",
    "    sample_id = index - file_lens_cumsum[file_id - 1] if file_id > 0 else index\n",
    "\n",
    "    return file_id, sample_id\n",
    "\n",
    "\n",
    "def load_cached_structed_ellipses(ellipses_path):\n",
    "    ellipses_list = []\n",
    "    ellipses_path = Path(ellipses_path)\n",
    "    ellipses_paths = natsorted(ellipses_path.glob(\"ellipses_batch_*.memmap\"))\n",
    "    ellipses_info_paths = natsorted(ellipses_path.glob(\"ellipses_batch_info_*.txt\"))\n",
    "    ellipses_indices_paths = natsorted(ellipses_path.glob(\"ellipses_indices_*.npy\"))\n",
    "\n",
    "    for ellipses_path, ellipses_info_path, ellipses_indices_path in zip(\n",
    "        ellipses_paths, ellipses_info_paths, ellipses_indices_paths\n",
    "    ):\n",
    "        ellipses = load_memmap(ellipses_path, ellipses_info_path)\n",
    "        ellipses_indices = np.load(ellipses_indices_path)\n",
    "\n",
    "        for index in range(ellipses_indices.shape[0]):\n",
    "            start_index, end_index = ellipses_indices[index]\n",
    "            ellipses_list.append(ellipses[start_index:end_index])\n",
    "\n",
    "    return ellipses_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_time_dataset(\n",
    "    split, time_window, num_train_frames, num_val_frames, ellipse_path, output_base_path\n",
    "):\n",
    "    output_data_path = output_base_path / split / \"cached_data\"\n",
    "    output_ellipse_path = output_base_path / split / \"cached_ellipse\"\n",
    "    os.makedirs(output_data_path, exist_ok=True)\n",
    "    os.makedirs(output_ellipse_path, exist_ok=True)\n",
    "\n",
    "    if split == \"train\":\n",
    "        nums = [0, num_train_frames]\n",
    "    elif split == \"val\":\n",
    "        nums = [num_train_frames, num_train_frames + num_val_frames]\n",
    "\n",
    "    num_frames_list, total_frames = get_nums(ellipse_path)\n",
    "    event_segment_list = []\n",
    "    ellipse_segment_list = []\n",
    "    batch_counter = 0\n",
    "    for index in tqdm(range(nums[0], nums[1])):\n",
    "        file_id, sample_id = get_index(num_frames_list, index)\n",
    "        events = load_events(file_id)\n",
    "        ellipse = load_cached_structed_ellipses(ellipse_path)[file_id][sample_id]\n",
    "        end_event_time = ellipse[\"t\"]\n",
    "        start_event_time = end_event_time - time_window\n",
    "        event_segment = slice_events_at_timepoints(\n",
    "            events, start_event_time, end_event_time\n",
    "        )\n",
    "        event_segment_list.append(event_segment)\n",
    "        ellipse_segment_list.append(ellipse)\n",
    "\n",
    "        if (index + 1) % batch_size == 0 or (index + 1) == total_frames - 1:\n",
    "            events_merged = merge_structed_arrays(event_segment_list)\n",
    "            event_indices = get_indices(event_segment_list)\n",
    "            create_memmap(\n",
    "                events_merged,\n",
    "                f\"{output_data_path}/events_batch_{batch_counter}.memmap\",\n",
    "                f\"{output_data_path}/events_batch_info_{batch_counter}.txt\",\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{output_data_path}/events_indices_{batch_counter}.npy\", event_indices\n",
    "            )\n",
    "            event_segment_list = []\n",
    "            batch_counter += 1\n",
    "\n",
    "    ellipses_merged = merge_structed_arrays(ellipse_segment_list)\n",
    "    ellipses_indices = get_indices(ellipse_segment_list)\n",
    "    create_memmap(\n",
    "        ellipses_merged,\n",
    "        f\"{output_ellipse_path}/ellipses_batch_0.memmap\",\n",
    "        f\"{output_ellipse_path}/ellipses_batch_info_0.txt\",\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{output_ellipse_path}/ellipses_indices_0.npy\",\n",
    "        ellipses_indices,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For fixed time dataset'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"For fixed time dataset\"\"\"\n",
    "\n",
    "# output_base_path = Path(\"/mnt/data2T/junyuan/Datasets/FixedTime10000Dataset\")\n",
    "# get_fixed_time_dataset(\n",
    "#     \"train\", 10000, num_train_frames, num_val_frames, ellipse_path, output_base_path\n",
    "# )\n",
    "# get_fixed_time_dataset(\n",
    "#     \"val\", 10000, num_train_frames, num_val_frames, ellipse_path, output_base_path\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_count_dataset(\n",
    "    split,\n",
    "    events_count,\n",
    "    num_train_frames,\n",
    "    num_val_frames,\n",
    "    ellipse_path,\n",
    "    output_base_path,\n",
    "):\n",
    "    output_data_path = output_base_path / split / \"cached_data\"\n",
    "    output_ellipse_path = output_base_path / split / \"cached_ellipse\"\n",
    "    os.makedirs(output_data_path, exist_ok=True)\n",
    "    os.makedirs(output_ellipse_path, exist_ok=True)\n",
    "\n",
    "    if split == \"train\":\n",
    "        nums = [0, num_train_frames]\n",
    "    elif split == \"val\":\n",
    "        nums = [num_train_frames, num_train_frames + num_val_frames]\n",
    "\n",
    "    num_frames_list, total_frames = get_nums(ellipse_path)\n",
    "    event_segment_list = []\n",
    "    ellipse_segment_list = []\n",
    "    batch_counter = 0\n",
    "    for index in tqdm(range(nums[0], nums[1])):\n",
    "        file_id, sample_id = get_index(num_frames_list, index)\n",
    "        events = load_events(file_id)\n",
    "        ellipse = load_cached_structed_ellipses(ellipse_path)[file_id][sample_id]\n",
    "        end_event_time = ellipse[\"t\"]\n",
    "        event_segment = slice_events_by_timestamp_and_count(\n",
    "            events, end_event_time, events_count\n",
    "        )\n",
    "        event_segment_list.append(event_segment)\n",
    "        ellipse_segment_list.append(ellipse)\n",
    "\n",
    "        if (index + 1) % batch_size == 0 or (index + 1) == total_frames - 1:\n",
    "            events_merged = merge_structed_arrays(event_segment_list)\n",
    "            event_indices = get_indices(event_segment_list)\n",
    "            create_memmap(\n",
    "                events_merged,\n",
    "                f\"{output_data_path}/events_batch_{batch_counter}.memmap\",\n",
    "                f\"{output_data_path}/events_batch_info_{batch_counter}.txt\",\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{output_data_path}/events_indices_{batch_counter}.npy\", event_indices\n",
    "            )\n",
    "            event_segment_list = []\n",
    "            batch_counter += 1\n",
    "\n",
    "    ellipses_merged = merge_structed_arrays(ellipse_segment_list)\n",
    "    ellipses_indices = get_indices(ellipse_segment_list)\n",
    "    create_memmap(\n",
    "        ellipses_merged,\n",
    "        f\"{output_ellipse_path}/ellipses_batch_0.memmap\",\n",
    "        f\"{output_ellipse_path}/ellipses_batch_info_0.txt\",\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{output_ellipse_path}/ellipses_indices_0.npy\",\n",
    "        ellipses_indices,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For fixed count dataset'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"For fixed count dataset\"\"\"\n",
    "\n",
    "# output_base_path = Path(\"/mnt/data2T/junyuan/Datasets/FixedCount1000Dataset\")\n",
    "# get_fixed_count_dataset(\n",
    "#     \"train\", events_count, num_train_frames, num_val_frames, ellipse_path, output_base_path\n",
    "# )\n",
    "# get_fixed_count_dataset(\n",
    "#     \"val\", events_count, num_train_frames, num_val_frames, ellipse_path, output_base_path\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_count_dataset_from_txt(\n",
    "    split,\n",
    "    events_count,\n",
    "    events_path,\n",
    "    ellipse_path,\n",
    "    output_base_path,\n",
    "):\n",
    "    output_data_path = output_base_path / split / \"cached_data\"\n",
    "    output_ellipse_path = output_base_path / split / \"cached_ellipse\"\n",
    "    os.makedirs(output_data_path, exist_ok=True)\n",
    "    os.makedirs(output_ellipse_path, exist_ok=True)\n",
    "\n",
    "    events = TxtProcessor(events_path).load_events_from_txt()\n",
    "    ellipses = TxtProcessor(ellipse_path).load_ellipses_from_txt()\n",
    "    total_frames = len(ellipses)\n",
    "    num_train_frames = int(total_frames * 0.8)\n",
    "    num_val_frames = total_frames - num_train_frames\n",
    "\n",
    "    if split == \"train\":\n",
    "        nums = [0, num_train_frames]\n",
    "    elif split == \"val\":\n",
    "        nums = [num_train_frames, num_train_frames + num_val_frames]\n",
    "        \n",
    "    event_segment_list = []\n",
    "    ellipse_segment_list = []\n",
    "    batch_counter = 0\n",
    "    for index in tqdm(range(nums[0], nums[1])):\n",
    "        ellipse = ellipses[index]\n",
    "        end_event_time = ellipse[\"t\"]\n",
    "        event_segment = slice_events_by_timestamp_and_count(\n",
    "            events, end_event_time, events_count\n",
    "        )\n",
    "        event_segment_list.append(event_segment)\n",
    "        ellipse_segment_list.append(ellipse)\n",
    "\n",
    "    events_merged = merge_structed_arrays(event_segment_list)\n",
    "    event_indices = get_indices(event_segment_list)\n",
    "    create_memmap(\n",
    "        events_merged,\n",
    "        f\"{output_data_path}/events_batch_{batch_counter}.memmap\",\n",
    "        f\"{output_data_path}/events_batch_info_{batch_counter}.txt\",\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{output_data_path}/events_indices_{batch_counter}.npy\", event_indices\n",
    "    )\n",
    "    event_segment_list = []\n",
    "    batch_counter += 1\n",
    "\n",
    "    ellipses_merged = merge_structed_arrays(ellipse_segment_list)\n",
    "    ellipses_indices = get_indices(ellipse_segment_list)\n",
    "    create_memmap(\n",
    "        ellipses_merged,\n",
    "        f\"{output_ellipse_path}/ellipses_batch_0.memmap\",\n",
    "        f\"{output_ellipse_path}/ellipses_batch_info_0.txt\",\n",
    "    )\n",
    "    np.save(\n",
    "        f\"{output_ellipse_path}/ellipses_indices_0.npy\",\n",
    "        ellipses_indices,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [00:00<00:00, 49834.27it/s]\n",
      "Merging arrays...: 100%|██████████| 824/824 [00:00<00:00, 5045.03it/s]\n",
      "Getting indices...: 824it [00:00, 375296.61it/s]\n",
      "Merging arrays...: 100%|██████████| 824/824 [00:00<00:00, 450131.09it/s]\n",
      "Getting indices...: 824it [00:00, 328496.01it/s]\n",
      "100%|██████████| 206/206 [00:00<00:00, 72485.46it/s]\n",
      "Merging arrays...: 100%|██████████| 206/206 [00:00<00:00, 4488.29it/s]\n",
      "Getting indices...: 206it [00:00, 290039.15it/s]\n",
      "Merging arrays...: 100%|██████████| 206/206 [00:00<00:00, 288104.91it/s]\n",
      "Getting indices...: 206it [00:00, 302424.44it/s]\n"
     ]
    }
   ],
   "source": [
    "events_path  = Path(\"/mnt/data2T/junyuan/eye-tracking/DeanDataset/events.txt\")\n",
    "ellipse_path = Path(\"/mnt/data2T/junyuan/eye-tracking/DeanDataset/ellipses.txt\")\n",
    "output_base_path = Path(\"/mnt/data2T/junyuan/eye-tracking/DeanDataset\")\n",
    "\n",
    "\n",
    "get_fixed_count_dataset_from_txt(\"train\", 5000, events_path, ellipse_path, output_base_path)\n",
    "get_fixed_count_dataset_from_txt(\"val\", 5000, events_path, ellipse_path, output_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_unet_dataset(\n",
    "    split,\n",
    "    events_count,\n",
    "    num_train_frames,\n",
    "    num_val_frames,\n",
    "    ellipse_path,\n",
    "    output_base_path,\n",
    "):\n",
    "    output_data_path = output_base_path / split / \"data\"\n",
    "    output_ellipse_path = output_base_path / split / \"label\"\n",
    "    os.makedirs(output_data_path, exist_ok=True)\n",
    "    os.makedirs(output_ellipse_path, exist_ok=True)\n",
    "\n",
    "    if split == \"train\":\n",
    "        nums = [0, num_train_frames]\n",
    "    elif split == \"val\":\n",
    "        nums = [num_train_frames, num_train_frames + num_val_frames]\n",
    "\n",
    "    num_frames_list, _ = get_nums(ellipse_path)\n",
    "\n",
    "    for index in tqdm(range(nums[0], nums[1])):\n",
    "        file_id, sample_id = get_index(num_frames_list, index)\n",
    "        events = load_events(file_id)\n",
    "        ellipse = load_cached_structed_ellipses(ellipse_path)[file_id][sample_id]\n",
    "        end_event_time = ellipse[\"t\"]\n",
    "        event_segment = slice_events_by_timestamp_and_count(\n",
    "            events, end_event_time, events_count\n",
    "        )\n",
    "        event_frame = to_frame_stack_numpy(\n",
    "            event_segment,\n",
    "            (346, 260, 2),\n",
    "            1,\n",
    "            \"causal_linear\",\n",
    "            event_segment['t'][0],\n",
    "            event_segment['t'][-1],\n",
    "            10,\n",
    "        )\n",
    "        if split == \"val\":\n",
    "            index = index - num_train_frames\n",
    "        event_frame_vis = visualize(event_frame)\n",
    "        save_image(event_frame_vis, f\"{output_data_path}/{index:05}.png\")\n",
    "\n",
    "        ellipse = convert_to_ellipse(ellipse)\n",
    "        canvas = np.zeros((260, 346, 3), dtype=np.uint8)\n",
    "        cv2.ellipse(canvas, ellipse, (255, 255, 255), -1)\n",
    "        save_image(canvas, f\"{output_ellipse_path}/{index:05}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For event unet dataset\"\"\"\n",
    "\n",
    "output_base_path = Path(\"/mnt/data2T/junyuan/Datasets/EventUNetDataset\")\n",
    "# get_event_unet_dataset(\n",
    "#     split=\"train\",\n",
    "#     events_count=2000,\n",
    "#     num_train_frames=num_train_frames,\n",
    "#     num_val_frames=num_val_frames,\n",
    "#     ellipse_path=ellipse_path,\n",
    "#     output_base_path=output_base_path,\n",
    "# )\n",
    "# get_event_unet_dataset(\n",
    "#     split=\"val\",\n",
    "#     events_count=2000,\n",
    "#     num_train_frames=num_train_frames,\n",
    "#     num_val_frames=num_val_frames,\n",
    "#     ellipse_path=ellipse_path,\n",
    "#     output_base_path=output_base_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_subfolders(directory):\n",
    "    directory_path = Path(directory)\n",
    "    subfolders = natsorted([f for f in directory_path.iterdir() if f.is_dir()])\n",
    "    return subfolders\n",
    "\n",
    "\n",
    "def find_and_copy_file(subfolders, timestamp, target_path, index):\n",
    "    target_path = Path(target_path)\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        png_file = subfolder / f\"{timestamp}.png\"\n",
    "        if png_file.exists():\n",
    "            output_path = target_path / f\"{index:05}.png\"\n",
    "            shutil.copy(png_file, output_path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "def get_rgb_unet_dataset(\n",
    "    split,\n",
    "    raw_path,\n",
    "    num_train_frames,\n",
    "    num_val_frames,\n",
    "    ellipse_path,\n",
    "    output_base_path,\n",
    "):\n",
    "    output_data_path = output_base_path / split / \"data\"\n",
    "    output_ellipse_path = output_base_path / split / \"label\"\n",
    "    os.makedirs(output_data_path, exist_ok=True)\n",
    "    os.makedirs(output_ellipse_path, exist_ok=True)\n",
    "\n",
    "    if split == \"train\":\n",
    "        nums = [0, num_train_frames]\n",
    "    elif split == \"val\":\n",
    "        nums = [num_train_frames, num_train_frames + num_val_frames]\n",
    "    num_frames_list, _ = get_nums(ellipse_path)\n",
    "\n",
    "    for index in tqdm(range(nums[0], nums[1])):\n",
    "        file_id, sample_id = get_index(num_frames_list, index)\n",
    "        ellipse = load_cached_structed_ellipses(ellipse_path)[file_id][sample_id]\n",
    "        timestamp = ellipse[\"t\"]\n",
    "        if split == \"val\":\n",
    "            index = index - num_train_frames\n",
    "        subfolders = list_subfolders(raw_path)\n",
    "        find_and_copy_file(subfolders, timestamp, output_data_path, index)\n",
    "        ellipse = convert_to_ellipse(ellipse)\n",
    "        canvas = np.zeros((260, 346, 3), dtype=np.uint8)\n",
    "        cv2.ellipse(canvas, ellipse, (255, 255, 255), -1)\n",
    "        save_image(canvas, f\"{output_ellipse_path}/{index:05}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For RGB UNet dataset\"\"\"\n",
    "\n",
    "output_base_path = Path(\"/mnt/data2T/junyuan/Datasets/RGBUNetDataset\")\n",
    "raw_path = Path('/mnt/data2T/junyuan/Datasets/datasets/DavisEyeCenterDatasetFrames')\n",
    "get_rgb_unet_dataset(\n",
    "    split=\"train\",\n",
    "    raw_path=raw_path,\n",
    "    num_train_frames=num_train_frames,\n",
    "    num_val_frames=num_val_frames,\n",
    "    ellipse_path=ellipse_path,\n",
    "    output_base_path=output_base_path,\n",
    ")\n",
    "# get_rgb_unet_dataset(\n",
    "#     split=\"val\",\n",
    "#     raw_path=raw_path,\n",
    "#     num_train_frames=num_train_frames,\n",
    "#     num_val_frames=num_val_frames,\n",
    "#     ellipse_path=ellipse_path,\n",
    "#     output_base_path=output_base_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def rename_png_files(directory):\n",
    "    # 获取目录路径\n",
    "    root_dir = Path(directory)\n",
    "\n",
    "    # 递归遍历目录下的所有png文件\n",
    "    for png_file in tqdm(root_dir.rglob(\"*.png\")):\n",
    "        # 获取文件的stem部分\n",
    "        stem = png_file.stem\n",
    "\n",
    "        # 分割stem并获取第二个部分\n",
    "        new_stem = stem.split(\"_\")[1]\n",
    "\n",
    "        # 构建新的文件名\n",
    "        new_filename = new_stem + png_file.suffix\n",
    "\n",
    "        # 重命名文件\n",
    "        png_file.rename(png_file.parent / new_filename)\n",
    "        # print(f\"Renamed {png_file} to {new_filename}\")\n",
    "\n",
    "\n",
    "# 调用函数并传入目录路径\n",
    "rename_png_files(\"/mnt/data2T/junyuan/Datasets/datasets/DavisEyeCenterDatasetFrames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 8999\n",
    "event_segment_time = load_event_segment(\n",
    "    index, \"/mnt/data2T/junyuan/Datasets/FixedTime10000Dataset/train/cached_data\", 5000\n",
    ")\n",
    "ellipse_time = load_ellipse(\n",
    "    index, \"/mnt/data2T/junyuan/Datasets/FixedTime10000Dataset/train/cached_ellipse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 8999\n",
    "event_segment_count = load_event_segment(\n",
    "    index, \"/mnt/data2T/junyuan/Datasets/FixedCount10000Dataset/train/cached_data\", 5000\n",
    ")\n",
    "ellipse_count = load_ellipse(\n",
    "    index, \"/mnt/data2T/junyuan/Datasets/FixedCount10000Dataset/train/cached_ellipse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ellipse_time, ellipse_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_segment_time.shape, event_segment_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frame = to_frame_stack_numpy(\n",
    "    event_segment_time,\n",
    "    (346, 260, 2),\n",
    "    1,\n",
    "    \"causal_linear\",\n",
    "    event_segment_time['t'][0],\n",
    "    event_segment_time['t'][-1],\n",
    "    10,\n",
    ")\n",
    "event_frame_vis = visualize(event_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_segment_count_frame = to_frame_stack_numpy(\n",
    "    event_segment_count,\n",
    "    (346, 260, 2),\n",
    "    1,\n",
    "    \"causal_linear\",\n",
    "    event_segment_count['t'][0],\n",
    "    event_segment_count['t'][-1],\n",
    "    10,\n",
    ")\n",
    "event_frame_count_vis = visualize(event_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_frame.max(), event_frame_vis.max(), event_segment_count_frame.max(), event_frame_count_vis.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ellipse = convert_to_ellipse(ellipse_time)\n",
    "draw_ellipse(event_frame_count_vis, ellipse)\n",
    "plt.imshow(event_frame_count_vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EvEye",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
